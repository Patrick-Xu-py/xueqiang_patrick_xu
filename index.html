<!DOCTYPE HTML>
<html lang="en">

<head>    
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-0B5LHBSZYY"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-0B5LHBSZYY');
  </script>

  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Xueqiang (Patrick) Xu</title>

  <meta name="author" content="Xueqiang Xu">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="icon" href="favicon.ico?v=1">
  <link rel="shortcut icon" href="favicon.ico?v=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
<meta name="google-site-verification" content="SppVkSFcpllgYfMj_yChDn5QreKfTWW1_cEwRTvVBMY" />
</head>

<body>
  <table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:1.5%;width:70%;vertical-align:middle">
              <p style="text-align:center">
                <name>Xueqiang (Patrick) Xu</name>
              </p>
              <p>
                I am currently in the MSCS program at <b>UIUC</b>, where I am advised by 
                Prof. <a href="http://hanj.cs.illinois.edu">Jiawei Han</a> and work closely with 
                Prof. <a href="https://cs.stanford.edu/people/jiaxuan/">Jiaxuan You</a>. 
                I completed my undergraduate studies at <b>UIUC</b> (2020‚Äì2024), graduating with 
                a Highest Honors B.S. in Computer Science.
              </p>
              <p style="text-align:center">
               ÂæêÂ≠¶Âº∫ &nbsp/&nbsp
                <a target="_blank" href="/cdn-cgi/l/email-protection#8cf4f4bdb5cce5e0e0e5e2e3e5ffa2e9e8f9">Email</a> &nbsp/&nbsp
                <!-- <a target="_blank" href="data/CV___Peiyang_Song.pdf">CV</a> &nbsp/&nbsp -->
                <a target="_blank"href="https://scholar.google.com/citations?user=YPYIX9EAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a target="_blank" href="https://github.com/Patrick-Xu-py">GitHub</a> &nbsp/&nbsp
		<a target="_blank" href="https://www.linkedin.com/in/xueqiang-xu/">LinkedIn</a> &nbsp/&nbsp
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/profile_photo.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/profile_photo.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
	<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
	      <p>
    <b>[Jan 2026]</b>    One paper on zero-shot entity structure extraction <a href="https://arxiv.org/abs/2506.04458">ZOES</a> has been accepted by EACL 2026 Main Conference.<br>
    <b>[Dec 2025]</b>    We released our paper on <a href="https://arxiv.org/abs/2512.16301">Adaptation of Agentic AI</a>, with public repository <a href="https://github.com/pat-jj/Awesome-Adaptation-of-Agentic-AI">here</a>. Hope you enjoy reading it!.<br>
    <b>[Aug 2025]</b> üî• Two papers accepted to EMNLP 2025: one in <a href="https://arxiv.org/abs/2505.14146">s3: Training Search Agent via RL</a>, and one in <a href="https://arxiv.org/abs/2505.19588">LogiCoL: Logically-Informed Contrastive Learning for Set-based Dense Retrieval</a>.<br>
    <b>[Jan 2025]</b> One paper on hierarchical text classification <a href="https://arxiv.org/abs/2403.00165">TELEClass</a> has been accepted by The Web Conference 2025 as a poster.<br>
  </p>
            </td>
          </tr>
		
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <!-- <p> I'm interested in <b>language and intelligence</b> in both humans and machines, particularly the role language plays in shaping intelligent behavior, which I study through comparisons between LLMs and humans. I analyze their behavioral capabilities and failures, examine internal mechanisms, and develop strategies to enhance intelligent machine systems.</p> -->
 
              <p>
                My research focuses on advancing <strong><em>knowledge-grounded scientific reasoning in large language models</em></strong>. 
                I study how to extract, structure, and leverage scientific knowledge so that LLMs can reason more reliably, 
                more transparently, and in ways that meaningfully support scientific discovery. 
                I approach this goal through three interconnected directions:
              </p>
              
              <ul>
                <li>
                  <strong>Structured Knowledge Extraction</strong> &mdash; developing methods that enable LLMs to extract 
                  <strong><em>entities, attributes, relations, and hierarchical schemas</em></strong> from scientific literature 
                  under weak or zero supervision. 
                  My work aims to transform unstructured papers into machine-interpretable scientific knowledge bases.
                </li>
              
                <li>
                  <strong>Knowledge-Augmented LLM Reasoning</strong> &mdash; integrating structured knowledge into 
                  LLMs' reasoning processes through <strong><em>retrieval, schema guidance, control vectors, 
                  and multi-hop reasoning</em></strong>. 
                  I investigate how explicit knowledge structures can improve LLM factuality, faithfulness, and problem-solving ability 
                  in scientific domains.
                </li>
              
                <li>
                  <strong>Scientific Agents and Reliability</strong> &mdash; building LLM-based scientific agents that can 
                  <strong><em>reason step-by-step and self-correct</em></strong>.  
                  I explore mechanisms for <em>trustworthy, explainable, and robust</em> reasoning pipelines to support 
                  real scientific workflows.
                </li>
              </ul>
              
              <p>
                These directions reflect a unified goal: combining the strengths of 
                <strong>structured knowledge</strong> and <strong>large language models</strong> to build 
                AI systems capable of <em>reliable, interpretable, and scientifically meaningful reasoning</em>. 
                If our interests align, feel free to reach out &mdash; I'm always excited to connect and collaborate!
              </p>
            </td>
          </tr>
    
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <heading>Selected Publications</heading>

          <tr onmouseout="zoes_stop()" onmouseover="zoes_start()" id="zoes">
            <td style="padding:5px;width:17%;vertical-align:middle">
              <div class="one">
                <div class="two" id='zoes_image'>
                  <img src='images/zoes/zoes-1.png' width="150">
                </div>
                <img src='images/zoes/zoes.png' width="150">
              </div>
              <script data-cfasync="false" src="/cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script type="text/javascript">
                function zoes_start() {
                  document.getElementById('zoes_image').style.opacity = "1";
                }

                function zoes_stop() {
                  document.getElementById('zoes_image').style.opacity = "0";
                }
                personality_stop()
              </script>
            </td>
            <td style="padding:20px;width:83%;vertical-align:middle">
              <a target="_blank" href="https://arxiv.org/abs/2506.04458">
                <papertitle>Zero-Shot Open-Schema Entity Structure Discovery</papertitle>
              </a>
              <br />
               <strong>Xueqiang Xu</strong>, <a target="_blank" href="https://jxiao13.web.engr.illinois.edu">Jinfeng Xiao</a>,
               <a target="_blank" href="https://research.ibm.com/people/james-barry">James Barry</a>,
               <a target="_blank" href="https://research.ibm.com/people/mohab-elkaref">Mohab Elkaref</a>,
               <a target="_blank" href="https://scholar.google.com/citations?user=GzLTey4AAAAJ&hl=en">Jiaru Zou</a>,
               <a target="_blank" href="https://pat-jj.github.io">Pengcheng Jiang</a>,
               <a target="_blank" href="https://yzhan238.github.io">Yunyi Zhang</a>,
               <a target="_blank" href="https://research.ibm.com/people/maxwell-giammona">Max Giammona</a>,
               <a target="_blank" href="https://research.ibm.com/people/geeth-r-de-mel-de-mel">Geeth de Mel</a>,
               <a target="_blank" href="https://hanj.cs.illinois.edu">Jiawei Han</a>
              <br />
              <em>EACL Main Conference</em>, 2026
              <br />
              <p><a target="_blank" href="https://arxiv.org/abs/2506.04458">Preprint</a></p>
              <p></p>
              <p>
                We introduce ZOES, a novel approach to entity structure extraction that does not require any schema or annotated samples. ZOES operates via a principled mechanism of enrichment, refinement, and unification, based on the insight that an entity and its associated structure are mutually reinforcing.
              </p>
            </td>
          </tr>

          <tr onmouseout="s3_stop()" onmouseover="s3_start()" id="llmrf">
            <td style="padding:5px;width:17%;vertical-align:middle">
              <div class="one">
                <div class="two" id='s3_image'>
                  <img src='images/s3/s3-1.png' width="150">
                </div>
                <img src='images/s3/s3-2.png' width="150">
              </div>
              <script type="text/javascript">
                function s3_start() {
                  document.getElementById('s3_image').style.opacity = "1";
                }

                function s3_stop() {
                  document.getElementById('s3_image').style.opacity = "0";
                }
                s3_stop()
              </script>
            </td>
            <td style="padding:20px;width:83%;vertical-align:middle">
              <a target="_blank" href="https://arxiv.org/abs/2505.14146">
                <papertitle>s3: You Don't Need That Much Data to Train a Search Agent via RL</papertitle>
              </a>
              <br />
              <a target="_blank" href="https://pat-jj.github.io">Pengcheng Jiang</a>, 
              <strong>Xueqiang Xu</strong>, 
              <a target="_blank" href="https://linjc16.github.io">Jiacheng Lin</a>,
              <a target="_blank" href="https://underline.io/speakers/203935-zifeng-wang">Zifeng Wang</a>,
              <a target="_blank" href="https://www.sunlab.org">Jimeng Sun</a>,
              and <a target="_blank" href="http://hanj.cs.illinois.edu">Jiawei Han</a>
              <br />
              <em>EMNLP Main Conference</em>, 2025
              <br />
              <p><a target="_blank" href="https://arxiv.org/abs/2505.14146">Preprint</a>     <a target="_blank" href="https://github.com/pat-jj/s3?tab=readme-ov-file">Code</a></p>
              
              <p></p>
              <p>
                In this work, we propose s3, a lightweight, model-agnostic framework that decouples the searcher from the generator using only 2.4k data in the RL training process.
              </p>
            </td>
          </tr>
          
          <tr onmouseout="adaptation_stop()" onmouseover="adaptation_start()" id="adaptation">
            <td style="padding:5px;width:17%;vertical-align:middle">
              <div class="one">
                <div class="two" id='adaptation_image'>
                  <img src='images/adaptation/adaptation-1.png' width="150">
                </div>
                <img src='images/adaptation/adaptation.png' width="150">
              </div>
              <script type="text/javascript">
                function adaptation_start() {
                  document.getElementById('adaptation_image').style.opacity = "1";
                }

                function adaptation_stop() {
                  document.getElementById('adaptation_image').style.opacity = "0";
                }
                adaptation_stop()
              </script>
            </td>
            <td style="padding:20px;width:83%;vertical-align:middle">
              <a target="_blank" href="https://arxiv.org/abs/2512.16301">
                <papertitle>Adaptation of Agentic AI</papertitle>
              </a>
              <br />
              <a target="_blank" href="https://pat-jj.github.io">Pengcheng Jiang</a>*, 
              <a target="_blank" href="https://linjc16.github.io">Jiacheng Lin</a>*, 
              <a target="_blank" href="https://zhiyiscs.github.io">Zhiyi Shi</a>*, 
              <a target="_blank" href="https://www.linkedin.com/in/zifengwang-ai">Zifeng Wang</a>,
              <a target="_blank" href="https://lumos23.github.io">Luxi He</a>,
              <a target="_blank" href="https://wuyichen-97.github.io">Yichen Wu</a>,
              <a target="_blank" href="https://maszhongming.github.io">Ming Zhong</a>,
              <a target="_blank" href="https://peiyang-song.github.io">Peiyang Song</a>,
              <a target="_blank" href="https://alex-q-z.github.io">Qizheng Zhang</a>,
              <a target="_blank" href="https://arthur-heng.github.io">Heng Wang</a>,
              <strong>Xueqiang Xu</strong>,
              <a target="_blank" href="https://hanwenxuthu.github.io">Hanwen Xu</a>,
              <a target="_blank" href="https://pengrui-han.github.io">Pengrui Han</a>,
              <a target="_blank" href="https://lemon-agreement-54e.notion.site/dylanzhang">Dylan Zhang</a>,
              <a target="_blank" href="https://gasolsun36.github.io">Jiashuo Sun</a>,
              <a target="_blank" href="https://ycq091044.github.io">Chaoqi Yang</a>,
              <a target="_blank" href="https://www.linkedin.com/in/kun-qian-7537611aa">Kun Qian</a>,
              <a target="_blank" href="https://www.linkedin.com/in/tianwng">Tian Wang</a>,
              <a target="_blank" href="https://www.linkedin.com/in/changran-hu">Changran Hu</a>,
              <a target="_blank" href="https://limanling.github.io">Manling Li</a>,
              <a target="_blank" href="https://researchers.mgh.harvard.edu/profile/4211743/Quanzheng-Li">Quanzheng Li</a>,
              <a target="_blank" href="https://haopeng-nlp.github.io">Hao Peng</a>,
              <a target="_blank" href="https://homes.cs.washington.edu/~swang">Sheng Wang</a>,
              <a target="_blank" href="https://shangjingbo1226.github.io">Jingbo Shang</a>,
              <a target="_blank" href="http://chaozhang.org">Chao Zhang</a>,
              <a target="_blank" href="https://cs.stanford.edu/~jiaxuan">Jiaxuan You</a>,
              <a target="_blank" href="https://liyuanlucasliu.github.io">Liyuan Liu</a>,
              <a target="_blank" href="https://lupantech.github.io">Pan Lu</a>,
              <a target="_blank" href="https://yuzhimanhua.github.io">Yu Zhang</a>,
              <a target="_blank" href="https://blender.cs.illinois.edu/hengji.html">Heng Ji</a>,
              <a target="_blank" href="https://yejinc.github.io">Yejin Choi</a>,
              <a target="_blank" href="https://dawnsong.io">Dawn Song</a>,
              <a target="_blank" href="https://www.sunlab.org">Jimeng Sun</a>,
              <a target="_blank" href="https://hanj.cs.illinois.edu">Jiawei Han</a>
              <strong>(* Equal Contribution)</strong>
              <br />
              <em>Preprint</em>, 2025
              <br />
              <p><a target="_blank" href="https://arxiv.org/abs/2512.16301">arXiv</a>     <a target="_blank" href="https://github.com/pat-jj/Awesome-Adaptation-of-Agentic-AI">Code</a></p>
              
              <p></p>
              <p>
                We unify the rapidly expanding research landscape of agentic AI systems into a systematic framework that spans both agent adaptations and tool adaptations. Cutting-edge agentic AI systems are built on foundation models that can be adapted to plan, reason, and interact with external tools to perform increasingly complex and specialized tasks.
              </p>
            </td>
          </tr>


          <tr onmouseout="teleclass_stop()" onmouseover="teleclass_start()" id="teleclass">
            <td style="padding:5px;width:17%;vertical-align:middle">
              <div class="one">
                <div class="two" id='teleclass_image'>
                  <img src='images/teleclass/teleclass-1.png' width="150">
                </div>
                <img src='images/teleclass/teleclass-2.png' width="150">
              </div>
              <script type="text/javascript">
                function teleclass_start() {
                  document.getElementById('teleclass_image').style.opacity = "1";
                }

                function teleclass_stop() {
                  document.getElementById('teleclass_image').style.opacity = "0";
                }
                teleclass_stop()
              </script>
            </td>
            <td style="padding:20px;width:83%;vertical-align:middle">
              <a target="_blank" href="https://arxiv.org/abs/2403.00165">
                <papertitle>TELEClass: Taxonomy Enrichment and LLM-Enhanced Hierarchical Text Classification with Minimal Supervision</papertitle>
              </a>
              <br />
              <a target="_blank" href="https://yzhan238.github.io">Yunyi Zhang</a>, 
              <a target="_blank" href="https://ruozhenyang.github.io">Ruozhen Yang</a>*, 
              <strong>Xueqiang Xu</strong>*, 
              <a target="_blank" href="https://scholar.google.com/citations?user=fK2e-v4AAAAJ">Rui Li</a>*,
              <a target="_blank" href="https://jxiao13.web.engr.illinois.edu">Jinfeng Xiao</a>,
              <a target="_blank" href="https://jiamings.github.io">Jiaming Shen</a>,
              and <a target="_blank" href="http://hanj.cs.illinois.edu">Jiawei Han</a> <strong>(* Equal Contribution)</strong>
              <br />
              <em>The Web Conference (WWW)</em>, 2025
              <br />
              <p><a target="_blank" href="https://arxiv.org/abs/2403.00165">Preprint</a>     <a target="_blank" href="https://github.com/yzhan238/TELEClass">Code</a></p>
              
              <p></p>
              <p>
                We propose TELEClass, which combines the general knowledge of LLMs and task-specific features mined from an unlabeled corpus. TELEClass automatically enriches the label taxonomy with class-indicative features and utilizes novel LLM-based data annotation and generation methods specifically tailored for hierarchical text classification.
              </p>
            </td>
          </tr>

          <tr onmouseout="logicol_stop()" onmouseover="logicol_start()" id="logicol">
            <td style="padding:5px;width:17%;vertical-align:middle">
              <div class="one">
                <div class="two" id='logicol_image'>
                  <img src='images/logical/logical-1.png' width="150">
                </div>
                <img src='images/logical/logical-2.png' width="150">
              </div>
              <script type="text/javascript">
                function logicol_start() {
                  document.getElementById('logicol_image').style.opacity = "1";
                }

                function logicol_stop() {
                  document.getElementById('logicol_image').style.opacity = "0";
                }
                logicol_stop()
              </script>
            </td>
            <td style="padding:20px;width:83%;vertical-align:middle">
              <a target="_blank" href="https://arxiv.org/abs/2505.19588">
                <papertitle>LogiCoL: Logically-Informed Contrastive Learning for Set-based Dense Retrieval</papertitle>
              </a>
              <br />
              <a target="_blank" href="https://yzshen.com">Yanzhen Shen</a>, 
              <a target="_blank" href="https://www.linkedin.com/in/sihao-chen">Sihao Chen</a>, 
              <strong>Xueqiang Xu</strong>, 
              <a target="_blank" href="https://yzhan238.github.io">Yunyi Zhang</a>,
              <a target="_blank" href="https://www.chaitanyamalaviya.com">Chaitanya Malaviya</a>,
              and <a target="_blank" href="https://www.cis.upenn.edu/~danroth/">Dan Roth</a>
              <br />
              <em>EMNLP Main Conference</em>, 2025
              <br />
              <p><a target="_blank" href="https://arxiv.org/abs/2505.19588">Preprint</a></p>
              
              <p></p>
              <p>
                We introduce LogiCoL, a logically-informed contrastive learning objective for dense retrievers that handles queries with logical connectives. LogiCoL learns to respect subset and mutually-exclusive set relations between query results via soft constraints expressed through t-norm, achieving improvements in both retrieval performance and logical consistency.
              </p>
            </td>
          </tr>

        </tbody></table>

	<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Awards</heading>
		<ul>
      <li>City Scholar at UIUC</li>
<li>Illinois Scholars Undergraduate Research</li>
<li>IIDAI scholar</li>
		</ul>
            </td>
          </tr>
        </tbody></table>



	      
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br />
              <p style="text-align:right;font-size:small;">
                Template from <a target="_blank" href="https://jonbarron.info/">Jon Barron</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>